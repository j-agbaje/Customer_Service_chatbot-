{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jgdqfHoSJeAb"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive for saving results and models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7yg9GxZeI8J",
        "outputId": "b600bc79-248b-4a77-a041-b78ea028e692"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD BEST MODEL\n",
        "print(\"Loading Model....\")\n",
        "MODEL_PATH = '/content/drive/MyDrive/chatbot_model_Higher_LR_Extended'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
        "print(\"Model loaded successfully!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiW4uu1NeEys",
        "outputId": "acbefbf4-7dc5-4d40-9d21-c6ee0d65f090"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Model....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n",
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/chatbot_model_Higher_LR_Extended.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_in_domain(query):\n",
        "    \"\"\"Check if query is related to customer service\"\"\"\n",
        "    domain_keywords = [\n",
        "        'order', 'cancel', 'refund', 'payment', 'shipping', 'delivery',\n",
        "        'account', 'invoice', 'subscription', 'track', 'return', 'purchase',\n",
        "        'help', 'issue', 'problem', 'support','password'\n",
        "    ]\n",
        "    for keyword in domain_keywords:\n",
        "        if keyword in query.lower():\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "zeexKIX8zWXJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # function for taking in input and returning chatbot output\n",
        "def display_output(user_input, history):\n",
        "\n",
        "    # fall back message if message is not in domain\n",
        "    if not is_in_domain(user_input):\n",
        "        fallback = (\"I apologize, but I can only assist with customer service queries \"\n",
        "                   \"related to orders, refunds, shipping, accounts, and payments. \"\n",
        "                   \"Please contact our support team for other inquiries at 1-800-123-4567.\")\n",
        "        partial = \"\"\n",
        "        for word in fallback.split():\n",
        "          partial += word + \" \"\n",
        "          time.sleep(0.05)\n",
        "          yield partial.strip()\n",
        "\n",
        "        return\n",
        "\n",
        "    query = f\"Answer the customer service query:{user_input}\" # format query to fit model input\n",
        "\n",
        "\n",
        "    inputs = tokenizer(query, return_tensors='tf', padding=True, truncation=True) # tokenize inut\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 256, num_beams=1, do_sample=False) # generate output\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True) # decode output\n",
        "    words = response.split()\n",
        "    words = response.split()\n",
        "    partial_response = \"\"\n",
        "    for word in words:\n",
        "        partial_response += word + \" \"\n",
        "        time.sleep(0.05)  # Add 50ms delay between words (adjust as needed)\n",
        "        yield partial_response.strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # for i in range(len(response)):\n",
        "    #     # time.sleep(0.1)\n",
        "    #     yield response[: i+1]\n",
        "\n"
      ],
      "metadata": {
        "id": "wy_UcqCC-hY3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "# gradio chatbot interface\n",
        "gr.ChatInterface(\n",
        "    fn=display_output,\n",
        "    type=\"messages\",\n",
        "    title=\"ðŸ’¬ Customer Support Assistant\",\n",
        "    description=(\n",
        "        \"Welcome to the **Customer Service Chatbot** powered by Google FLAN-T5 and the Bitext dataset.\\n\\n\"\n",
        "        \"You can ask questions related to customer support, such as:\\n\"\n",
        "        \"- Cancelling or tracking an order\\n\"\n",
        "        \"- Requesting a refund\\n\"\n",
        "        \"- Updating your account details and more FAQs\\n\\n\"\n",
        "        \"ðŸ’¡ *Type your question below and press Enter or click 'Submit' to get a response.*\"\n",
        "    ),\n",
        "    examples=[\n",
        "        [\"I want to cancel my order #12345\"],\n",
        "        [\"Can you help me track my shipment?\"],\n",
        "        [\"I'd like to request a refund for my last purchase.\"],\n",
        "        [\"How do I change my account password?\"],\n",
        "        [\"What's your return policy?\"],\n",
        "        [\"I want to change my shipping address for order 98765\"],\n",
        "    ],\n",
        "    textbox=gr.Textbox(\n",
        "        placeholder=\"Ask your question here... (e.g. 'How can I cancel my order?')\",\n",
        "        container=False,\n",
        "        autoscroll=True,\n",
        "        scale=7\n",
        "    ),\n",
        "    theme=gr.themes.Base(primary_hue=\"blue\").set(\n",
        "        body_background_fill=\"#f1f5f9\",  # Light slate gray - easy on eyes\n",
        "        body_background_fill_dark=\"#f1f5f9\",\n",
        "        body_text_color=\"#0f172a\",       # Dark text for light background\n",
        "        body_text_color_dark=\"#0f172a\",\n",
        "        block_label_text_color=\"#334155\", # Slightly lighter for labels\n",
        "        block_title_text_color=\"#1e293b\",\n",
        "        input_background_fill=\"#ffffff\",  # White input fields\n",
        "        button_primary_text_color=\"#ffffff\",\n",
        "        color_accent=\"#0284c7\",  # Blue accent\n",
        "        color_accent_soft=\"#0284c7\",\n",
        "    ),\n",
        ").launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "dpfXkwQR-10-",
        "outputId": "eded4c33-1fdc-4252-983f-db46146cfbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b1af794e83af85565a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b1af794e83af85565a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}